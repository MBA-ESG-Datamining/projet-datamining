---
title: "Datamining - Regression Logistique"
author: "Clara"
date: "3/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

## Gestion des données 


```
# library:
library(gmodels)
library(dplyr)
library(MASS)
rm(list=ls())
# Importer des données
my_data <- readxl::read_excel("/Users/Clara/Documents/1_ESG_MBA/Cours /Datamining/Fichier de donnees - Credit.xls")
# Présentation générale de l'ensemble de données
summary(my_data)
# Renommer des variables
colnames(my_data) <- as.vector(gsub(" ", "_", as.vector(colnames(my_data))))
colnames(my_data) <- as.vector(gsub("'", "_", colnames(my_data)))
my_data
```

## Valeurs manquantes


```
# On fait en sorte qu'il n'y a pas de valeur manquante dans l'ensemble de données
ifelse(sapply(my_data, FUN = 
                function(x) {sum(is.na(x))}) == 0, "NO MISSING VALUE", 
       sapply(my_data, FUN = function(x) {sum(is.na(x))}))

par(mfrow = c(1,2))
boxplot(my_data$Score_1, main = "Score 1")
boxplot(my_data$Score_2, main = "Score 2")
```


## Modélisation & Interprétation


```
# Objectif: 
# Construire un modèle de classification pour prédire si le client est ou non "bon" en se basant sur ses antécédents de crédit
# À partir de là, la banque peut décider si elle doit prêter de l'argent au client.
# Pour cette raison, on prend la variable "Type de client" comme variable exploratoire
# On examine la variable exploratoire à travers le graphique à secteurs montrant la répartition des bons et mauvais clients
typeclient <- as.data.frame(
  prop.table(table(my_data$Type_de_client)) * 100
)
pct <- round(typeclient[,2]/sum(typeclient[,2])*100)
typeclient[,1] <- paste(typeclient[,1], pct)
typeclient[,1] <- paste(typeclient[,1], "%", sep = "")
pie(typeclient[,2], typeclient[,1], main = "Type de client")

```

# Statistiques descriptives pour les variables nominales
# Age du client
CrossTable(my_data$Age_du_client, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format=c("SPSS"))

# Ancienneté
CrossTable(my_data$Ancienneté, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format=c("SPSS"))

# Domiciliation du salaire
CrossTable(my_data$Domiciliation_du_salaire, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format=c("SPSS"))

# Situation familiale
CrossTable(my_data$Situation_familiale, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format=c("SPSS"))

# Domiciliation de l'épargne
CrossTable(my_data$Domiciliation_de_l_épargne, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format=c("SPSS"))

# Profession
CrossTable(my_data$Profession, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

# Moyenne encours
CrossTable(my_data$Moyenne_encours, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

# Moyenne des mouvements
CrossTable(my_data$Moyenne_des_mouvements, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

# Cumul des débits
CrossTable(my_data$Cumul_des_débits, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

# Autorisation de découvert
CrossTable(my_data$Autorisation_de_découvert, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

# Interdiction de chéquier
CrossTable(my_data$Interdiction_de_chéquier, my_data$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = FALSE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

# Regroupement de variables
my_data$Situation_familiale[my_data$Situation_familiale == "veuf" | my_data$Situation_familiale == "divorcé"] <- "divorcé/veuf"
my_data$Domiciliation_de_l_épargne[my_data$Domiciliation_de_l_épargne == "plus de 100K épargne" | my_data$Domiciliation_de_l_épargne == "de 10 à 100K épargne"] <- "plus de 10K épargne"



# Restructurer les données pour la régression logit
# Package requis: install.packages("fastDummies")
# On fait en sorte que le Idenfiant_Client est dans son type correct
# sinon les dummy_cols le prendront en compte dans le processus de binarisation
my_data$Identifiant_Client <- as.numeric(my_data$Identifiant_Client)

# Ici, on fait juste un petit truc pour se préparer à la fonction dummy_cols
# Comme il supprimera le premier mannequin pour éviter la multicolinéarité,
# il ne créera pas automatiquement la variable fictive pour "Bon client"
# Cependant, il est plus intéressant de voir la probabilité d'être un bon client
# C'est pourquoi on réordonne l'ensemble de données pour que le premier élément de la variable soit "Mauvais_client"
my_data <- my_data[order(my_data$Type_de_client, decreasing = TRUE),] 

# Créer le jeu de données principal contenant toutes les bonnes variables
my_data_main <- fastDummies::dummy_cols(my_data, remove_first_dummy = FALSE ) # Pour éviter la problème de multicollinéaire

# Renommer les variables dans le nouvel ensemble de données
colnames(my_data_main) <- as.vector(gsub(" ", "_", as.vector(colnames(my_data_main))))
colnames(my_data_main) <- as.vector(gsub("__", "_", colnames(my_data_main)))
colnames(my_data_main) <- as.vector(gsub("'", "_", colnames(my_data_main)))

# # Convertir les données de type numérique en données de type facteur
my_data_main <- as.data.frame(my_data_main)
my_data_main[,16] <- as.factor(my_data_main[,17])

# Echantillonage
# Tirage aléaoire et sans remise des 70% des individus de l'échantillon
# On initialise le tirage aléatoire afin de retomber sur nos pieds à chaque fois
set.seed(1000000000)
cut_level <- sort(sample(nrow(my_data_main), nrow(my_data_main) * 0.7))
# Echantillon d'apprentissage
train_set <- my_data_main[cut_level,]
# Echantillon de test
test_set <- my_data_main[-cut_level,]

# Executer le modèle logit sur l'échantillon d'apprentissage
my_model <- glm(Type_de_client_Bon_client 
                ~ Age_du_client_de_23_à_39_ans + Age_du_client_de_40_à_50_ans + Age_du_client_moins_de_23_ans
                + Ancienneté_anc._de_4_à_6_ans + Ancienneté_anc._1_an_ou_moins + Ancienneté_anc._de_1_à_4_ans
                + Domiciliation_du_salaire_Non_domicilié
                + Profession_cadre + Profession_autre
                + Moyenne_encours_de_2_à_5_K_encours + Moyenne_encours_moins_de_2K_encours
                + Moyenne_des_mouvements_de_10_à_30K_mouvt + Moyenne_des_mouvements_de_30_à_50K_mouvt + Moyenne_des_mouvements_moins_10_K_mouvt
                + Cumul_des_débits_de_40_à_100_débits + Cumul_des_débits_moins_de_40_débits
                + Autorisation_de_découvert_découvert_autorisé + Interdiction_de_chéquier_chéquier__autorisé
                + Situation_familiale_célibataire + Situation_familiale_marié
                + Domiciliation_de_l_épargne_moins_de_10K_épargne + Domiciliation_de_l_épargne_pas_d_épargne
                , data = train_set, family = binomial(link = 'logit'))
summary(my_model)


## Modélisation & Interprétation
```
# Choisir le meilleur modèle en utilisant la fonction stepAIC
# qui nous permet de sélectionner automatiquement un modèle plus généralisable en terme de robustesse

# Exécuter le modèle stepwise
my_model_trivial <- "~1" #On définit un modèle trivial réduit à la constante
my_model_temp <- glm(Type_de_client_Bon_client ~ 1, data = train_set, family = binomial(link = 'logit'))
my_model_stepwise <- stepAIC(my_model_temp, 
                           scope = list(lower = my_model_trivial, upper = my_model), 
                           trace = TRUE, data = train_set, direction = "both")
summary(my_model_stepwise)

# Exécuter le modèle final sur l'échantillon d'apprentissage
my_model_main <- glm(formula = Type_de_client_Bon_client ~ Domiciliation_du_salaire_Non_domicilié
                     + Interdiction_de_chéquier_chéquier__autorisé + Moyenne_encours_moins_de_2K_encours
                     + Ancienneté_anc._1_an_ou_moins + Ancienneté_anc._de_4_à_6_ans
                     + Profession_cadre + Cumul_des_débits_moins_de_40_débits
                     + Cumul_des_débits_de_40_à_100_débits + Moyenne_encours_de_2_à_5_K_encours
                     + Age_du_client_moins_de_23_ans + Situation_familiale_célibataire
                     + Moyenne_des_mouvements_moins_10_K_mouvt, 
                     family = binomial(link = "logit"), 
                     data = train_set)
summary(my_model_main)

# Calculer les odds-ratios
OR <- as.data.frame(exp(cbind(Odd_Ratio <- coef(my_model_main), confint(my_model_main))))
colnames(OR) <- c("Odds Ratio", "Borne inférieure", "Borne supérieure")

# Calculer le matrice de confusion
# On réalise les memes étapes pour chaque échantillion d'apprentissage et test

attributes(my_model_main)

# Echantillon d'apprentissage
## Matrice de classement en effectif
# On produit des prédictions sur l'échantillion d'apprentissage à partir du prédicteur linéaire
train_set_p <- cbind(train_set, predict(my_model_main, train_set, type = "link", se = TRUE))

# On obtient les probabilités correspondantes à l'inverse des fit par la fonction logistique
train_set_p <- within(train_set_p, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit))
  UL <- plogis(fit + (1.96 * se.fit))
})

# On dénote les observations qui ont la probabilité supérieure à 0.5 par 1, et 0 pour le cas de l'inverse
train_set_p <- cbind(train_set_p, pred.Type_de_client_Bon_client = factor(ifelse(train_set_p$PredictedProb > 0.5, 1, 0)))

# Calculer la matrice de confusion pour l'échantillon d'apprentissage
matrix_confusion_train <- as.matrix(table(train_set_p$pred.Type_de_client_Bon_client, train_set_p$Type_de_client_Bon_client))
matrix_confusion_train <- as.data.frame(unclass(matrix_confusion_train))
colnames(matrix_confusion_train) <- c("Classé_Mauvais_client", "Classé_Bon_client")
rownames(matrix_confusion_train) <- c("Mauvais_client", "Bon_client")
matrix_confusion_train

## Matrice de classement en pourcentages
matrix_pct_train <- data.frame(matrix(NA, ncol = 2, nrow = 2)) 
colnames(matrix_pct_train) <- c("Bien_classé", "Mal_classé")
rownames(matrix_pct_train) <- c("Mauvais_client", "Bon_client")

# On crée un fonctione trivial pour formater les pourcentages
percent <- function(x, digits = 2, format = "f", ...) {
  paste0(formatC(100 * as.numeric(x), format = format, digits = digits, ...), "%")
}

matrix_pct_train[1,1] <- percent(matrix_confusion_train[1,1] / (matrix_confusion_train [1,1] + matrix_confusion_train[1,2]))
matrix_pct_train[2,1] <- percent(matrix_confusion_train[2,2] / (matrix_confusion_train [2,1] + matrix_confusion_train[2,2]))
matrix_pct_train[1,2] <- percent(matrix_confusion_train[1,2] / (matrix_confusion_train [1,1] + matrix_confusion_train[1,2]))
matrix_pct_train[2,2] <- percent(matrix_confusion_train[2,1] / (matrix_confusion_train [2,1] + matrix_confusion_train[2,2]))

matrix_pct_train

# Echantillion test
# Matrice de classement en effectif
test_set_p <- cbind(test_set, predict(my_model_main, newdata = test_set, type = "response", se = TRUE))
test_set_p <- cbind(test_set_p, pred.Type_de_client_Bon_client <- factor(ifelse(test_set_p$fit > 0.5, 1, 0)))
matrix_confusion_test <- as.matrix(table(test_set_p$pred.Type_de_client_Bon_client, test_set_p$Type_de_client_Bon_client))
matrix_confusion_test <- as.data.frame(unclass(matrix_confusion_test))
colnames(matrix_confusion_test) <- c("Classé_Mauvais_client", "Classé_Bon_client")
rownames(matrix_confusion_test) <- c("Mauvais_client", "Bon_client")
matrix_confusion_test     

## Matrice de classement en pourcentages
matrix_pct_test <- data.frame(matrix(NA, ncol = 2, nrow = 2)) 
colnames(matrix_pct_test) <- c("Bien_classé", "Mal_classé")
rownames(matrix_pct_test) <- c("Mauvais_client", "Bon_client")

matrix_pct_test[1,1] <- percent(matrix_confusion_test[1,1] / (matrix_confusion_test [1,1] + matrix_confusion_test[1,2]))
matrix_pct_test[2,1] <- percent(matrix_confusion_test[2,2] / (matrix_confusion_test [2,1] + matrix_confusion_test[2,2]))
matrix_pct_test[1,2] <- percent(matrix_confusion_test[1,2] / (matrix_confusion_test [1,1] + matrix_confusion_test[1,2]))
matrix_pct_test[2,2] <- percent(matrix_confusion_test[2,1] / (matrix_confusion_test [2,1] + matrix_confusion_test[2,2]))

matrix_pct_test

# Pivot table
my_data_main$rule_Score1 <- ifelse(my_data_main$Score_1 > mean(my_data_main$Score_1), "Prédit Bon", "Prédit Mauvais")
CrossTable(my_data_main$rule_Score1, my_data_main$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = TRUE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

my_data_main$rule_Score2 <- ifelse(my_data_main$Score_2 > mean(my_data_main$Score_2), "Prédit Bon", "Prédit Mauvais")
CrossTable(my_data_main$rule_Score1, my_data_main$Type_de_client, expected = FALSE, prop.r=TRUE, prop.c = TRUE,
           prop.t = FALSE, prop.chisq = FALSE, format = c("SPSS"))

```